{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 5 - Automated ML \n",
    "\n",
    "In the previous lab you have trained a first machine learning (ML) model on the automobile prices dataset. Model training is a very iterative process and typically requires multiple iterations to improve upon an existing model. \n",
    "\n",
    "Automated machine learning - or Auto ML for short - is the process of automating the time consuming, iterative tasks of machine learning model development. It allows data scientists, analysts, and developers to build ML models with high scale, efficiency, and productivity all while sustaining model quality. Automated ML is based on a breakthrough from our [Microsoft Research division](https://arxiv.org/abs/1705.05355).\n",
    "\n",
    "Apply automated ML when you want Azure Machine Learning to train and tune a model for you using the target metric you specify. The service then iterates through ML algorithms paired with feature selections, where each iteration produces a model with a training score. The higher the score, the better the model is considered to fit your data.\n",
    "With automated machine learning, you'll accelerate the time it takes to get production-ready ML models with great ease and efficiency.\n",
    "\n",
    "<img src=\"https://docs.microsoft.com/en-us/azure/machine-learning/service/media/tutorial-auto-train-models/flow2.png\" style=width:500px/>\n",
    "\n",
    "\n",
    "## When to use Auto ML\n",
    "\n",
    "Automated ML democratizes the machine learning model development process, and empowers its users, no matter their data science expertise, to identify an end-to-end machine learning pipeline for any problem.\n",
    "Data scientists, analysts and developers across industries can use automated ML to:\n",
    "\n",
    "- Implement machine learning solutions without extensive programming knowledge\n",
    "- Save time and resources\n",
    "- Leverage data science best practices\n",
    "- Provide agile problem-solving\n",
    "\n",
    "Automated machine learning picks an algorithm and hyperparameters for you and generates a model ready for deployment if you choose to do so. After doing so, it will create another model with a different algorithm and different hyperparameters, trying to improve upon the error metric specified.\n",
    "\n",
    "Much like before, we first need to establish the connection to our Azure ML workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import azureml.core\n",
    "from azureml.core.experiment import Experiment\n",
    "from azureml.core.workspace import Workspace\n",
    "from azureml.core.dataset import Dataset\n",
    "from azureml.train.automl import AutoMLConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting to workspace\n",
    "\n",
    "By now you are probably familiar wit this first step of establishing a connection to our Azure ML workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()\n",
    "\n",
    "# choose a name for experiment\n",
    "experiment_name = 'german_credit_data_automl'\n",
    "\n",
    "experiment=Experiment(ws, experiment_name)\n",
    "\n",
    "output = {}\n",
    "output['Subscription ID'] = ws.subscription_id\n",
    "output['Workspace'] = ws.name\n",
    "output['Resource Group'] = ws.resource_group\n",
    "output['Location'] = ws.location\n",
    "output['Experiment Name'] = experiment.name\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "outputDf = pd.DataFrame(data = output, index = [''])\n",
    "outputDf.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remote compute target\n",
    "\n",
    "Previous tutorials have run inside of your Compute Instance. In this tutorial, you are now going to train a machine learning model on **remote** compute resources. You'll use the training and deployment workflow for Azure Machine Learning in a Python Jupyter notebook. You can then use the notebook as a template to train your own machine learning model with your own data at a later point in time.\n",
    "\n",
    "The selected VM size \"Standard DS11 v2\" features 4 v-cores and 14 GB of RAM which will be sufficient for our purposes. You may select larger VMs as well as a higher node count to build a larger cluster suitable for your purposes. Note that VMs including GPUs are also available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# Choose a name for your CPU cluster\n",
    "cpu_cluster_name = \"cpu-cluster\"\n",
    "\n",
    "# Verify that cluster does not exist already\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=cpu_cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS11_V2',\n",
    "                                                           min_nodes = 0, max_nodes=2)\n",
    "    compute_target = ComputeTarget.create(ws, cpu_cluster_name, compute_config)\n",
    "\n",
    "compute_target.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we are going to retrieve our dataset. Here the fact that the dataset is already centrally registered comes in handy as the compute target will also be available to access it without any additional work required. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.get_by_name(ws, name='german_credit_dataset')\n",
    "\n",
    "training_data, validation_data = dataset.random_split(percentage=0.8, seed=23)\n",
    "label_column_name = 'Risk'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is time to define what the Auto ML should be doing exactly.\n",
    "\n",
    "- *experiment_timeout_hours* determines how long the Auto ML job is allowed to run at most. Once this amount of time is exceeded, the experiment will stop regardless of current results. \n",
    "- *primary_metric* specifices which model error metric to optimize for. Refer to [this list](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-understand-automated-ml#classification) to view all possible metrics\n",
    "- *featurization* allows Auto ML to first pre-process the data before fitting a model. More information about the types of pre-processing that can be applied may be viewed [here](https://docs.microsoft.com/en-us/azure/machine-learning/service/concept-automated-ml#preprocessing) and can include missing value imputation.\n",
    "- *n_cross_validations* ensures that the Auto ML engine will run K-fold cross-validation with K being the number of cross-validations that will be run. Alternatively, it's also possible to use Monte Carlo cross-validation or a custom validation (e.g. for imbalanced datasets).\n",
    "\n",
    "The [documentation on the AutoMLConfig class](https://docs.microsoft.com/en-us/python/api/azureml-train-automl-client/azureml.train.automl.automlconfig.automlconfig?view=experimental) lists a myriad of other arguments that could be passed to define the Auto ML run. A particularly useful one would be *experiment_exit_score* which serves as an exit criterion and terminates the experiment upon achieving a specific error metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_settings = {\n",
    "    \"n_cross_validations\": 3,\n",
    "    \"primary_metric\": 'average_precision_score_weighted',\n",
    "    \"featurization\": 'auto',\n",
    "    \"enable_early_stopping\": False,\n",
    "    \"max_concurrent_iterations\": 2, # This is a limit for testing purpose, please increase it as per cluster size\n",
    "    \"experiment_timeout_hours\": 0.25, # This is a time limit for testing purposes, remove it for real use cases, this will drastically limit ablity to find the best model possible\n",
    "    \"verbosity\": logging.INFO,\n",
    "}\n",
    "\n",
    "automl_config = AutoMLConfig(task = 'classification',\n",
    "                             debug_log = 'automl_errors.log',\n",
    "                             compute_target = compute_target,\n",
    "                             training_data = training_data,\n",
    "                             label_column_name = label_column_name,\n",
    "                             **automl_settings\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To submit the Auto ML experiment for run, we need to run the next code cell. As with previous models that we trained, you may navigate to the [Azure ML Studio](https://ml.azure.com) and look for the progress in the *Experiments* page. Look for the experiment corresponding with the name of the experiment you have assigned in the code. When clicking on the Run ID of the run that's currently executing, you can then click the *Models* tab which will show the same information as the output below but in the web portal.\n",
    "\n",
    "Note that this will take at least 15 minutes (time specified for *experiment_timeout_hours*) plus some additional time to actually allocate the resources for the compute target in Azure ML as we have previously set the minimum number of nodes to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_run = experiment.submit(automl_config, show_output = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the Auto ML process has completed, we may inspect the individual runs in the portal or using the widget below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "RunDetails(remote_run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A model explanation will automatically be created for the best model. This can also be viewed in [Azure ML Studio](https://ml.azure.com). To view it, under *Experiments* click the name of the experiment of your AutoML run (here we used <code>german_credit_data_automl</code> if you have not changed it). In the list of runs, select the *Run ID* of your last run (you may only see one). This will open the details page as shown below where you click on *Models*.\n",
    "\n",
    "<img src=\"images/automl-run.jpg\" alt=\"Drawing\" style=\"width: 800px;\"/>\n",
    "\n",
    "Now all models trained in this run are being displayed. The column *Explained* shows that the explanation dashboard is only available for the best model. Click on the link *View explanation* as shown below.\n",
    "\n",
    "<img src=\"images/automl-view-explanation.jpg\" alt=\"Drawing\" style=\"width: 800px;\"/>\n",
    "\n",
    "By default, the explanation will show the **Global Importance** of features in the model. Click on *Summary Importance* to view more detailed information.\n",
    "\n",
    "<img src=\"images/automl-explanations.jpg\" alt=\"Drawing\" style=\"width: 800px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disclaimer\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
